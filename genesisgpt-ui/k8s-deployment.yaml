apiVersion: apps/v1
kind: Deployment
metadata:
  name: k8sgpt-ui
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: k8sgpt-ui
  template:
    metadata:
      labels:
        app: k8sgpt-ui
    spec:
      containers:
      - name: k8sgpt-ui
        image: your-registry/k8sgpt-ui:latest
        ports:
        - containerPort: 3000
        env:
        - name: K8SGPT_URL
          value: "http://k8sgpt-service:8090"
---
apiVersion: v1
kind: Service
metadata:
  name: k8sgpt-ui-service
  namespace: default
spec:
  selector:
    app: k8sgpt-ui
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: LoadBalancer  # Or NodePort/ClusterIP based on your needs
---
# Update K8sGpt deployment to run as server
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k8sgpt-server
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: k8sgpt-server
  template:
    metadata:
      labels:
        app: k8sgpt-server
    spec:
      containers:
      - name: k8sgpt
        image: your-registry/k8sgpt:latest
        command: ["./k8sgpt", "server"]
        ports:
        - containerPort: 8090
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: openai-secret
              key: api-key
        - name: GINTOOLS_URL
          value: "http://gintools-service:8080"
        - name: PORT
          value: "8090"
---
apiVersion: v1
kind: Service
metadata:
  name: k8sgpt-service
  namespace: default
spec:
  selector:
    app: k8sgpt-server
  ports:
  - protocol: TCP
    port: 8090
    targetPort: 8090
  type: ClusterIP